{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66b35a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json \n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "my_cmap = plt.get_cmap(\"viridis\")\n",
    "\n",
    "from sympy import lambdify\n",
    "import sympy as sp\n",
    "import sklearn\n",
    "import sklearn.metrics\n",
    "\n",
    "from symbolicgpt.models import GPT, GPTConfig, PointNetConfig\n",
    "from symbolicgpt.utils import processDataFiles, CharDataset,\\\n",
    "        sample_from_model, lossFunc\n",
    "                         \n",
    "from scipy.optimize import minimize, least_squares    \n",
    "\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "\n",
    "#\n",
    "import glob\n",
    "\n",
    "\n",
    "\n",
    "from symr.metrics import compute_complexity, compute_tree_distance, compute_exact_equivalence,\\\n",
    "        compute_r2, compute_r2_truncated, compute_relative_error, compute_isclose_accuracy,\\\n",
    "        compute_r2_over_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cca678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for running benchmarks\n",
    "\n",
    "distribution_type = \"uniform\"\n",
    "# for normal distribution, use mean and standard deviation.\n",
    "# for uniform distribution the range is the min and max values\n",
    "distribution_range = [-.990, 1.0]\n",
    "number_points = 200\n",
    "number_trials = 100 # seeds will be trial number\n",
    "logging = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617ce9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if(0):\n",
    "    complex_1 = \"1.0*x0/(1.0*x0*1.0*exp(1.0*x0)*1.0*exp(1.0*sin(1.0*x0+1.0))+1.0*exp(1.0*x0)*1.0*exp(1.0*sin(1.0*x0+1.0)))+1.0\"\n",
    "    complex_2 = \"1.0*sqrt(1.0*abs(1.0*sqrt(1.0*abs(1.0*x0+1.0))))*1.0*sin(1.0*x0/(1.0*x0+1.0)+1.0/(1.0*x0+1.0))+1.0\"\n",
    "    complex_3 = \"1.0*sqrt(1.0*abs(1.0*x0/(1.0*x0+1.0)+1.0/(1.0*x0+1.0)))+1.0*sqrt(1.0*abs(1.0*exp(1.0*x0)))+1.0\"\n",
    "    complex_4 = \"1.0*sqrt(1.0*abs(1.0*x0))+1.0/(x0*1.0*sqrt(1.0*abs(1.0*x0))*1.0*sqrt(1.0*abs(1.0*x0)))+1.0\"\n",
    "    complex_5 = \"1.0*x0/(1.0*x0*1.0*sqrt(1.0*abs(1.0*log(1.0*x0)))+1.0*sqrt(1.0*abs(1.0*log(1.0*x0))))+1.0\"\n",
    "    complex_6 = \"1.0*x0**2*1.0*sqrt(1.0*abs(1.0*x0+1.0))+1.0*x0+1.0*x0/(1.0*x0)+1.0*log(1.0*x0+1.0)+1.0\"\n",
    "    complex_7 = \"1.0*sqrt(1.0*abs(1.0*x0*1.0*sqrt(1.0*abs(1.0*x0))/(1.0*x0+1.0)+1.0/(1.0*x0+1.0)))+1.0\"\n",
    "    complex_8 = \"1.0*x0**2+1.0*x0+1.0*exp(1.0*x0)/1.0*sqrt(1.0*abs(1.0*sqrt(1.0*abs(1.0*x0+1.0))))+1.0\"\n",
    "\n",
    "\n",
    "    sample_meta = {complex_1: (-.9, 1., number_points, -3,-1.1,1, 3),\n",
    "                   complex_2: (-.9, 1., number_points, -3,-1.1,1, 3),\n",
    "                   complex_3: (-0.9, 1., number_points, -3,-1,1, 3),\n",
    "                   complex_4: (0.1, 2., number_points, 2, 3, 3, 4),\n",
    "                   complex_5: (1.01, 2, number_points, 2, 3, 3, 4),\n",
    "                   complex_6: (-.9, 3., number_points, 3, 5, 5, 7),\n",
    "                   complex_7: (-0.9, 1., number_points, -3,-1.1, 1, 3),\n",
    "                   complex_8: (-0.9, 1., number_points, -3,-1.1, 1, 3),              }\n",
    "    set_name = \"generated_complex\"\n",
    "    \n",
    "elif(1):\n",
    "    complex_1 = \"sin(x0 * exp(x0))\"\n",
    "    complex_2 = \"x0 + log(x0**4)\"\n",
    "    complex_3 = \"1+x0*sin(1/x0)\"\n",
    "    complex_4 = \"sqrt(x0**3) * log(x0**2)\"\n",
    "    complex_5 = \"(x0+x0**3) / (1+x0*cos(x0**2))\"\n",
    "    complex_6 = \"x0 / (sqrt(x0**2 + sin(x0)))\"\n",
    "    complex_7 = \"cos((x0+sin(x0))/ (x0**3+x0*log(x0**2)))\"\n",
    "    complex_8 = \"(exp(x0) * (1+sqrt(1+x0) + cos(x0**2)))/ x0**2\"\n",
    "\n",
    "    # sampling meta are (a,b,c,d,e,f,g) tuples, e.g. c samples in the range from a to b\n",
    "    # d,e and f,g are the min and max values for validation input ranges\n",
    "\n",
    "    sample_meta = {complex_1: (-5., 5., number_points, -7,-5, 5,7),\n",
    "                   complex_2: (-5., 5., number_points, -7,-5, 5,7),\n",
    "                   complex_3: (-5., 5., number_points, -7,-5, 5,7),\n",
    "                   complex_4: (-5., 5., number_points, -7,-5, 5,7),\n",
    "                   complex_5: (-1., .5, number_points, -2, -1., .5, 1.25),\n",
    "                   complex_6: (-5., 5., number_points, -7,-5, 5,7),\n",
    "                   complex_7: (-5., 5., number_points, -7,-5, 5,7),\n",
    "                   complex_8: (.1, 5., number_points, -7,-5, 5,7),\n",
    "                  }            \n",
    "\n",
    "    set_name = \"AB_complex\"\n",
    "    \n",
    "    \n",
    "benchmark_eqns = [complex_1, complex_2, complex_3, complex_4, \\\n",
    "        complex_5, complex_6, complex_7, complex_8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2a1c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_bfgs = True\n",
    "\n",
    "if use_bfgs:\n",
    "    my_method = \"valipour_w_bfgs\"\n",
    "else:\n",
    "    \n",
    "    my_method = \"valipour_no_bfgs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b7dded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize equations\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "for number, fn in enumerate(benchmark_eqns):\n",
    "\n",
    "    my_fn = sp.lambdify(\"x0\", expr=fn)\n",
    "    \n",
    "    (bottom, top, c,d,e,f,g) = sample_meta[fn]\n",
    "    \n",
    "    step_size = (top-bottom)/10000\n",
    "    \n",
    "    x = np.arange(bottom, top, step_size)\n",
    "    \n",
    "    my_color = my_cmap(number/len(benchmark_eqns))\n",
    "    plt.plot(x, my_fn(x), color=my_color, label = f\"{set_name}-{1+number}\")\n",
    "    \n",
    "plt.legend()\n",
    "plt.title(f\"{set_name} benchmark equations\")\n",
    "\n",
    "plt.figure()\n",
    "for number, fn in enumerate(benchmark_eqns):\n",
    "\n",
    "    my_fn = sp.lambdify(\"x0\", expr=fn)\n",
    "    \n",
    "    (bottom, top, c,d,e,f,g) = sample_meta[fn]\n",
    "    \n",
    "    step_size = (top-bottom)/10000\n",
    "    \n",
    "  \n",
    "    x = np.arange(d,e, step_size)\n",
    "    my_color = my_cmap(number/len(benchmark_eqns))\n",
    "    plt.plot(x, my_fn(x), color=my_color, label= f\"{set_name}-{1+number} val\", alpha=0.69)\n",
    "       \n",
    "plt.legend()\n",
    "\n",
    "for number, fn in enumerate(benchmark_eqns):\n",
    "\n",
    "    my_fn = sp.lambdify(\"x0\", expr=fn)\n",
    "    \n",
    "    (bottom, top, c,d,e,f,g) = sample_meta[fn]\n",
    "    \n",
    "    step_size = (top-bottom)/10000\n",
    "  \n",
    "    x = np.arange(f,g, step_size)\n",
    "    my_color = my_cmap(number/len(benchmark_eqns))\n",
    "    plt.plot(x, my_fn(x), color=my_color, label= f\"{set_name}-{1+number} val\", alpha=0.69)\n",
    "\n",
    "plt.title(f\"{set_name} benchmark validation regions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0cf461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from symbolicGPT.py in Valipour\n",
    "\n",
    "embeddingSize = 512\n",
    "numPoints = [20,21]\n",
    "numVars = 1\n",
    "numYs = 1\n",
    "method = \"EMB_SUM\"\n",
    "variableEmbedding = \"NOT_VAR\"\n",
    "\n",
    "# create the model                                                              \n",
    "pconf = PointNetConfig(embeddingSize=embeddingSize,                             \n",
    "                       numberofPoints=numPoints[1]-1,                           \n",
    "                       numberofVars=numVars,                                    \n",
    "                       numberofYs=numYs,                                        \n",
    "                       method=method,                                           \n",
    "                       variableEmbedding=variableEmbedding)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cb14a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "blockSize = 64\n",
    "maxNumFiles = 100\n",
    "const_range = [-2.1, 2.1]\n",
    "decimals = 8\n",
    "trainRange = [-3.0,3.0]\n",
    "\n",
    "target = \"Skeleton\"\n",
    "addVars = True if variableEmbedding == 'STR_VAR' else False\n",
    "path = os.path.join(\"./symbolicgpt\", \"datasets\", \"exp_test_temp\", \"Train\", \"*.json\")\n",
    "my_device = torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "files = glob.glob(path)[:maxNumFiles]                                       \n",
    "text = processDataFiles(files) \n",
    "chars = sorted(list(set(text))+['_','T','<','>',':']) # extract unique characters from the text before converting the text to a list, # T is for the test data\n",
    "text = text.split('\\n') # convert the raw text to a set of examples         \n",
    "trainText = text[:-1] if len(text[-1]) == 0 else text    \n",
    "vocab_size = 49\n",
    "\n",
    "train_dataset = CharDataset(text, blockSize, chars, numVars=numVars,        \n",
    "                numYs=numYs, numPoints=numPoints, target=target, addVars=addVars, \n",
    "                const_range=const_range, xRange=trainRange, decimals=decimals, augment=False)\n",
    "\n",
    "                 \n",
    "mconf = GPTConfig(vocab_size, blockSize,           \n",
    "                  n_layer=8, n_head=8, n_embd=embeddingSize,                    \n",
    "                  padding_idx=train_dataset.paddingID)   \n",
    "\n",
    "model = GPT(mconf, pconf)      \n",
    "\n",
    "# # load the best model before training                                         \n",
    "\n",
    "model_name = \"XYE_1Var_30-31Points_512EmbeddingSize_SymbolicGPT_GPT_PT_EMB_SUM_Skeleton_Padding_NOT_VAR_MINIMIZE.pt\"\n",
    "model_path = os.path.join(\"symbolicgpt\", \"Models\", model_name)\n",
    "model.load_state_dict(torch.load(model_path))                                   \n",
    "model = model.eval().to(my_device)\n",
    "\n",
    "char_dict = {index:elem for index, elem in enumerate(chars[:])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933f407b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "columns = \"eqn, seed, pred, target, correct, mse, r2_ood, r2_id, \"\n",
    "columns += \"target_complexity, complexity, method, range_low, range_high, \"\n",
    "columns += \"number_points, val_low0, val_high0, val_lo1, val_high1\"\n",
    "\n",
    "eval_tag = f\"eval_complex_{my_method}_{int(time.time())}\"\n",
    "\n",
    "if logging:\n",
    "    with open(f\"{eval_tag}.csv\", \"w\") as f:\n",
    "        f.write(columns)\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "variables = torch.tensor([1])\n",
    "temperature = 1.0\n",
    "top_k = 0.0\n",
    "top_p = 0.7\n",
    "do_sample = False\n",
    "inputs = torch.tensor([[23]]) # assume 23 is start token '<' \n",
    "model.to(torch.device(\"cpu\"));\n",
    "\n",
    "accuracies = []\n",
    "all_mses = []\n",
    "all_mse_sds = []\n",
    "\n",
    "all_r2_means = []\n",
    "all_r2_sds = []\n",
    "\n",
    "all_tree_distances = []\n",
    "all_ares = []\n",
    "\n",
    "all_tree_distance_sds = []\n",
    "all_are_sds = []\n",
    "\n",
    "catastrophic_failure_count = 0\n",
    "for hh, eqn in enumerate(benchmark_eqns):\n",
    "    equivalents = []\n",
    "    mses = []\n",
    "    \n",
    "    r2s = []\n",
    "    complexities = []\n",
    "    ares = []\n",
    "    tree_distances = []\n",
    "    \n",
    "    target_complexity = compute_complexity(eqn)\n",
    "    \n",
    "    for trial in range(number_trials):\n",
    "        \n",
    "        np.random.seed(trial)\n",
    "        torch.manual_seed(trial)\n",
    "        \n",
    "        my_fn = sp.lambdify(\"x0\", expr=eqn)\n",
    "        \n",
    "        (bottom, top, number_samples, d, e, f, g) = sample_meta[eqn]\n",
    "        x = np.random.rand(number_samples, 1) \\\n",
    "                * (top-bottom) \\\n",
    "                + bottom\n",
    "        \n",
    "        y = my_fn(x)\n",
    "        \n",
    "        x = torch.tensor(x.transpose(1,0)[None,:,:])\n",
    "        y = torch.tensor(y.transpose(1,0)[None,:,:])\n",
    "        \n",
    "        points = torch.cat([x,y], dim=1).float()\n",
    "        \n",
    "        \n",
    "        pred_outputs = sample_from_model(model, inputs, \n",
    "            blockSize, points=points,\\\n",
    "            variables=variables, temperature=temperature,\\\n",
    "            sample=do_sample, top_k=top_k, top_p=top_p)\n",
    "        \n",
    "        string_output = [char_dict[elem.item()] for elem in pred_outputs[0]]\n",
    "        pred_skeleton = \"\".join(string_output).split(\">\")[0][1:].replace(\"s\",\"x\").replace(\"q\",\"s\").replace(\"***\",\"**\")\n",
    "   \n",
    "        best_eqn = None\n",
    "        best_fn = None\n",
    "        tgt_eqn = sp.simplify(eqn)\n",
    "        try:     \n",
    "\n",
    "            # train a regressor to find the constants (too slow)                \n",
    "            c = [1.0 for i,x in enumerate(pred_skeleton) if x=='C'] # initialize coefficients as 1\n",
    "            # c[-1] = 0 # initialize the constant as zero                       \n",
    "            #b = [(-2,2) for i,x in enumerate(predicted) if x=='C']  # bounds on variables\n",
    "\n",
    "            if use_bfgs:\n",
    "            \n",
    "                optimized = minimize(lossFunc, c, args=(pred_skeleton, x.numpy(), y.numpy()), method=\"BFGS\")                                          \n",
    "\n",
    "                constants_placed = 0\n",
    "\n",
    "                pred_expression = \"\"\n",
    "\n",
    "                for my_char in pred_skeleton:\n",
    "\n",
    "                    if my_char == \"C\":\n",
    "                        pred_expression += f\"{optimized.x[constants_placed]}\"\n",
    "                        constants_placed += 1\n",
    "                    else:\n",
    "                        pred_expression += my_char\n",
    "            else:\n",
    "                constants_placed = 0\n",
    "\n",
    "                pred_expression = \"\"\n",
    "\n",
    "                for my_char in pred_skeleton:\n",
    "\n",
    "                    if my_char == \"C\":\n",
    "                        pred_expression += f\"{1.0}\"\n",
    "                        constants_placed += 1\n",
    "                    else:\n",
    "                        pred_expression += my_char\n",
    "            \n",
    "\n",
    "            print(pred_expression)\n",
    "            \n",
    "            #tgt_eqn = sp.simplify(eqn)\n",
    "            best_eqn = sp.simplify(pred_expression)\n",
    "            print(best_eqn)\n",
    "\n",
    "            tgt_fn = sp.lambdify(\"x0\", expr=eqn)\n",
    "            best_fn = sp.lambdify(\"x0\", expr=pred_expression.replace(\"x1\",\"x0\"))\n",
    "\n",
    "            is_correct = 1.0 * (sp.simplify(best_eqn - tgt_eqn) == 0) \n",
    "            \n",
    "            my_mse_1 = np.mean((tgt_fn(x.numpy()) - best_fn(x.numpy()))**2)\n",
    "            my_mse_0 = np.mean((tgt_fn(x.numpy()) - (best_fn(x.numpy())-1.0) )**2)\n",
    "            \n",
    "            my_mse = min([my_mse_1, my_mse_0])\n",
    "            \n",
    "            id_x = np.arange(bottom, top, (top-bottom)/1000).reshape(-1, 1)\n",
    "\n",
    "            bigger_x = np.append(np.arange(d,e, (e-d)/500).reshape(-1, 1),\\\n",
    "                                 np.arange(f,g, (g-f)/500).reshape(-1,1))\n",
    "\n",
    "            bigger_y_true = tgt_fn(bigger_x)\n",
    "            bigger_y_pred = best_fn(bigger_x)\n",
    "            \n",
    "            id_y_true = tgt_fn(id_x)\n",
    "            id_y_pred = best_fn(id_x)\n",
    "\n",
    "            if np.isfinite(bigger_y_pred.mean()):\n",
    "                my_r2 = sklearn.metrics.r2_score(bigger_y_true, bigger_y_pred)\n",
    "            else:\n",
    "                my_r2 = np.nan\n",
    "            \n",
    "            if np.isfinite(id_y_pred.mean()):\n",
    "                my_r2_id = sklearn.metrics.r2_score(id_y_true, id_y_pred)\n",
    "            else:\n",
    "                my_r2_id = np.nan\n",
    "\n",
    "            #assert np.isfinite(id_y_pred.mean()), \"not finite\"\n",
    "            \n",
    "            #assert np.isfinite(bigger_y_pred.mean()), \"not finite\"\n",
    "            \n",
    "            my_complexity = compute_complexity(best_eqn)\n",
    "            #import pdb; pdb.set_trace()\n",
    "            my_ted = compute_tree_distance(eqn, best_eqn)\n",
    "            my_are = compute_relative_error(id_y_true, id_y_pred)\n",
    "\n",
    "            complexities.append(my_complexity)\n",
    "            mses.append(my_mse)\n",
    "            r2s.append(my_r2_id)\n",
    "            equivalents.append(is_correct)\n",
    "            \n",
    "            tree_distances.append(my_ted)\n",
    "            ares.append(my_are)\n",
    "\n",
    "\n",
    "        except:\n",
    "            error_msg = f\"evaluation failed with predicted expression {pred_skeleton}.\"\n",
    "            wright = \"incorrect\"\n",
    "            \n",
    "            catastrophic_failure_count += 1\n",
    "            is_correct = 0\n",
    "            \n",
    "            my_mse = np.nan\n",
    "            my_r2 = np.nan\n",
    "            my_r2_id = np.nan\n",
    "            my_complexity = None\n",
    "            \n",
    "        wright = \"correct\" if is_correct else \"incorrect\"\n",
    "\n",
    "        correct = 1 if is_correct else 0\n",
    "        \n",
    "        try:\n",
    "            msg = f\"eqn {hh+1}, trial {trial} predicted {wright} equation: \\n    predicted: {best_eqn}\\n\"\n",
    "            msg +=f\"    target   : {tgt_eqn}\"\n",
    "            msg += f\" with mse {mses[-1]:.3}\\n\"\n",
    "        except:\n",
    "            msg = \"\"\n",
    "        print(msg)\n",
    "\n",
    "        #columns = \"eqn, seed, pred, target, correct, mse, method, range_low, range_high, r2, number_points\"\n",
    "        if logging:\n",
    "            results = f\"{eqn}, {hh}, {best_eqn}, {tgt_eqn}, {correct}, {my_mse}, {my_r2}, \"\\\n",
    "                    f\"{my_r2_id}, {target_complexity}, {my_complexity}, \"\\\n",
    "                    f\" {my_method}, {bottom}, {top}, {number_samples}, {d}, {e}, {f}, {g}\"\n",
    "\n",
    "            with open(f\"{eval_tag}.csv\", \"a\") as f:\n",
    "                f.write(results)\n",
    "                f.write(\"\\n\")\n",
    "                \n",
    "    msg = f\"accuracy for equation {hh+1}: {np.mean(equivalents)}\"\\\n",
    "            f\" with mean mse: {np.mean(mses):3}, running total failure count: {catastrophic_failure_count}\\n\"\n",
    "    print(msg)\n",
    "    if len(mses):\n",
    "        accuracies.append(np.mean(equivalents))\n",
    "        all_mses.append(np.mean(mses))\n",
    "        all_mse_sds.append(np.std(mses))\n",
    "        all_r2_means.append(np.mean(r2s))\n",
    "        all_r2_sds.append(np.std(r2s))\n",
    "\n",
    "        all_ares.append(np.mean(ares))\n",
    "        all_tree_distances.append(np.mean(tree_distances))\n",
    "\n",
    "        all_are_sds.append(np.std(ares))\n",
    "        all_tree_distance_sds.append(np.std(tree_distances))\n",
    "    else:\n",
    "        accuracies.append(0.0)\n",
    "        all_mses.append(float(\"inf\"))\n",
    "        all_mse_sds.append(float(\"inf\"))\n",
    "        all_r2_means.append(-float(\"inf\"))\n",
    "        all_r2_sds.append(float(\"inf\"))\n",
    "\n",
    "        all_ares.append(float(\"inf\"))\n",
    "        all_tree_distances.append(float(\"inf\"))\n",
    "\n",
    "        all_are_sds.append(float(\"inf\"))\n",
    "        all_tree_distance_sds.append(float(\"inf\"))\n",
    "    \n",
    "failure_msg = f\"\\nTotal failure count: {catastrophic_failure_count}, of {len(benchmark_eqns)*number_trials}\"\n",
    "failure_msg += f\" = {catastrophic_failure_count / (len(benchmark_eqns)*number_trials)}\"\n",
    "print(failure_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efbf1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "msg = f\"{my_method} accuracies\\n\"\n",
    "print(failure_msg)\n",
    "\n",
    "for ii, eqn in enumerate(benchmark_eqns):\n",
    "    \n",
    "    msg += f\"\\n  complex-{ii+1}, exact equ. accuracy: {accuracies[ii]:5f}, \"\\\n",
    "            f\"\\ntree edit distance: {all_tree_distances[ii]:.5} +/- {all_tree_distance_sds[ii]:.5} \"\\\n",
    "            f\"\\nmse: {all_mses[ii]:.5} +/- {all_mse_sds[ii]:.5} \"\\\n",
    "            f\"\\nrelative absolute error: {all_ares[ii]:.5} +/- {all_are_sds[ii]:.5} \"\\\n",
    "            f\"\\nr^2 (i.d): {all_r2_means[ii]:.5} +/- {all_r2_sds[ii]:.5}\\n\\n\"\n",
    "    \n",
    "    msg += f\"  {sp.expand(eqn)} \\n\"\n",
    "\n",
    "if logging:\n",
    "    summary_file = f\"{eval_tag}_summary.txt\"\n",
    "    with open(summary_file, \"w\") as f:\n",
    "        f.write(msg)\n",
    "        \n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a38a0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Total failure count: 200, of 800 = 0.25\n",
    "valipour_w_bfgs accuracies\n",
    "\n",
    "  complex-1, exact equ. accuracy: 0.000000, \n",
    "tree edit distance: 19.38 +/- 2.6068 \n",
    "mse: 0.46741 +/- 0.3956 \n",
    "relative absolute error: 4.1322e+09 +/- 5.9063e+09 \n",
    "r^2 (i.d): -2.708 +/- 4.6607\n",
    "\n",
    "  sin(x0*exp(x0)) \n",
    "\n",
    "  complex-2, exact equ. accuracy: 0.000000, \n",
    "tree edit distance: 16.3 +/- 1.7059 \n",
    "mse: nan +/- nan \n",
    "relative absolute error: nan +/- nan \n",
    "r^2 (i.d): nan +/- nan\n",
    "\n",
    "  x0 + log(x0**4) \n",
    "\n",
    "  complex-3, exact equ. accuracy: 0.000000, \n",
    "tree edit distance: 18.52 +/- 1.3452 \n",
    "mse: 0.080003 +/- 0.014802 \n",
    "relative absolute error: 0.13585 +/- 0.004742 \n",
    "r^2 (i.d): 0.0095249 +/- 0.014791\n",
    "\n",
    "  x0*sin(1/x0) + 1 \n",
    "\n",
    "  complex-4, exact equ. accuracy: 0.000000, \n",
    "tree edit distance: inf +/- inf \n",
    "mse: inf +/- inf \n",
    "relative absolute error: inf +/- inf \n",
    "r^2 (i.d): -inf +/- inf\n",
    "\n",
    "  sqrt(x0**3)*log(x0**2) \n",
    "\n",
    "  complex-5, exact equ. accuracy: 0.000000, \n",
    "tree edit distance: 34.0 +/- 0.0 \n",
    "mse: 0.014393 +/- 0.0017051 \n",
    "relative absolute error: 0.79621 +/- 0.092582 \n",
    "r^2 (i.d): 0.99361 +/- 0.00033622\n",
    "\n",
    "  x0**3/(x0*cos(x0**2) + 1) + x0/(x0*cos(x0**2) + 1) \n",
    "\n",
    "  complex-6, exact equ. accuracy: 0.000000, \n",
    "tree edit distance: inf +/- inf \n",
    "mse: inf +/- inf \n",
    "relative absolute error: inf +/- inf \n",
    "r^2 (i.d): -inf +/- inf\n",
    "\n",
    "  x0/sqrt(x0**2 + sin(x0)) \n",
    "\n",
    "  complex-7, exact equ. accuracy: 0.000000, \n",
    "tree edit distance: 40.94 +/- 5.6477 \n",
    "mse: 0.1896 +/- 0.10013 \n",
    "relative absolute error: 3.5634 +/- 17.851 \n",
    "r^2 (i.d): -6090.1 +/- 5.1363e+04\n",
    "\n",
    "  cos(x0/(x0**3 + x0*log(x0**2)) + sin(x0)/(x0**3 + x0*log(x0**2))) \n",
    "\n",
    "  complex-8, exact equ. accuracy: 0.000000, \n",
    "tree edit distance: 36.7 +/- 3.1417 \n",
    "mse: nan +/- nan \n",
    "relative absolute error: nan +/- nan \n",
    "r^2 (i.d): nan +/- nan\n",
    "\n",
    "  sqrt(x0 + 1)*exp(x0)/x0**2 + exp(x0)*cos(x0**2)/x0**2 + exp(x0)/x0**2 \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3290d303",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Total failure count: 200, of 800 = 0.25\n",
    "valipour_no_bfgs accuracies\n",
    "\n",
    "  complex-1, exact equ. accuracy: 0.000000, \n",
    "tree edit distance: 17.28 +/- 0.69397 \n",
    "mse: 1.1009 +/- 0.10597 \n",
    "relative absolute error: 1.3742e+10 +/- 1.759e+09 \n",
    "r^2 (i.d): -10.76 +/- 0.02368\n",
    "\n",
    "  sin(x0*exp(x0)) \n",
    "\n",
    "  complex-2, exact equ. accuracy: 0.000000, \n",
    "tree edit distance: 16.3 +/- 1.7059 \n",
    "mse: nan +/- nan \n",
    "relative absolute error: nan +/- nan \n",
    "r^2 (i.d): nan +/- nan\n",
    "\n",
    "  x0 + log(x0**4) \n",
    "\n",
    "  complex-3, exact equ. accuracy: 0.000000, \n",
    "tree edit distance: 18.0 +/- 0.0 \n",
    "mse: 1.4787e+125 +/- 4.0004e+125 \n",
    "relative absolute error: 4.2579e+60 +/- 0.0 \n",
    "r^2 (i.d): -5.4681e+125 +/- 2.2546e+110\n",
    "\n",
    "  x0*sin(1/x0) + 1 \n",
    "\n",
    "  complex-4, exact equ. accuracy: 0.000000, \n",
    "tree edit distance: inf +/- inf \n",
    "mse: inf +/- inf \n",
    "relative absolute error: inf +/- inf \n",
    "r^2 (i.d): -inf +/- inf\n",
    "\n",
    "  sqrt(x0**3)*log(x0**2) \n",
    "\n",
    "  complex-5, exact equ. accuracy: 0.000000, \n",
    "tree edit distance: 32.0 +/- 0.0 \n",
    "mse: 3.2605 +/- 0.41506 \n",
    "relative absolute error: 11.32 +/- 1.7764e-15 \n",
    "r^2 (i.d): -1.5806 +/- 2.2204e-16\n",
    "\n",
    "  x0**3/(x0*cos(x0**2) + 1) + x0/(x0*cos(x0**2) + 1) \n",
    "\n",
    "  complex-6, exact equ. accuracy: 0.000000, \n",
    "tree edit distance: inf +/- inf \n",
    "mse: inf +/- inf \n",
    "relative absolute error: inf +/- inf \n",
    "r^2 (i.d): -inf +/- inf\n",
    "\n",
    "  x0/sqrt(x0**2 + sin(x0)) \n",
    "\n",
    "  complex-7, exact equ. accuracy: 0.000000, \n",
    "tree edit distance: 27.86 +/- 0.51029 \n",
    "mse: 1.6557e+04 +/- 1.6452e+05 \n",
    "relative absolute error: 3.0704e+09 +/- 1.1191e+10 \n",
    "r^2 (i.d): -4.2884e+22 +/- 1.5631e+23\n",
    "\n",
    "  cos(x0/(x0**3 + x0*log(x0**2)) + sin(x0)/(x0**3 + x0*log(x0**2))) \n",
    "\n",
    "  complex-8, exact equ. accuracy: 0.000000, \n",
    "tree edit distance: 33.48 +/- 2.9137 \n",
    "mse: 3.7353e+125 +/- 7.3283e+125 \n",
    "relative absolute error: 7.8466e+59 +/- 4.4094e+59 \n",
    "r^2 (i.d): -2.3779e+122 +/- 1.3363e+122\n",
    "\n",
    "  sqrt(x0 + 1)*exp(x0)/x0**2 + exp(x0)*cos(x0**2)/x0**2 + exp(x0)/x0**2 \n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
