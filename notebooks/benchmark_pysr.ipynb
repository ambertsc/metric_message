{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66b35a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json \n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "my_cmap = plt.get_cmap(\"viridis\")\n",
    "from sympy import lambdify\n",
    "import sympy as sp\n",
    "\n",
    "from pysr import PySRRegressor\n",
    "\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "\n",
    "# for r-squared score\n",
    "import sklearn\n",
    "import sklearn.metrics\n",
    "\n",
    "\n",
    "from symr.metrics import compute_complexity, compute_tree_distance, compute_exact_equivalence,\\\n",
    "        compute_r2, compute_r2_truncated, compute_relative_error, compute_isclose_accuracy,\\\n",
    "        compute_r2_over_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cca678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for running benchmarks\n",
    "\n",
    "distribution_type = \"uniform\"\n",
    "# for normal distribution, use mean and standard deviation.\n",
    "# for uniform distribution the range is the min and max values\n",
    "distribution_range = [-.0, 4.0]\n",
    "\n",
    "number_points = 200\n",
    "number_trials = 100 # seeds will be trial number\n",
    "logging = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa1a079",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_method = \"PYSR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617ce9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if(0):\n",
    "    complex_1 = \"1.0*x0/(1.0*x0*1.0*exp(1.0*x0)*1.0*exp(1.0*sin(1.0*x0+1.0))+1.0*exp(1.0*x0)*1.0*exp(1.0*sin(1.0*x0+1.0)))+1.0\"\n",
    "    complex_2 = \"1.0*sqrt(1.0*abs(1.0*sqrt(1.0*abs(1.0*x0+1.0))))*1.0*sin(1.0*x0/(1.0*x0+1.0)+1.0/(1.0*x0+1.0))+1.0\"\n",
    "    complex_3 = \"1.0*sqrt(1.0*abs(1.0*x0/(1.0*x0+1.0)+1.0/(1.0*x0+1.0)))+1.0*sqrt(1.0*abs(1.0*exp(1.0*x0)))+1.0\"\n",
    "    complex_4 = \"1.0*sqrt(1.0*abs(1.0*x0))+1.0/(x0*1.0*sqrt(1.0*abs(1.0*x0))*1.0*sqrt(1.0*abs(1.0*x0)))+1.0\"\n",
    "    complex_5 = \"1.0*x0/(1.0*x0*1.0*sqrt(1.0*abs(1.0*log(1.0*x0)))+1.0*sqrt(1.0*abs(1.0*log(1.0*x0))))+1.0\"\n",
    "    complex_6 = \"1.0*x0**2*1.0*sqrt(1.0*abs(1.0*x0+1.0))+1.0*x0+1.0*x0/(1.0*x0)+1.0*log(1.0*x0+1.0)+1.0\"\n",
    "    complex_7 = \"1.0*sqrt(1.0*abs(1.0*x0*1.0*sqrt(1.0*abs(1.0*x0))/(1.0*x0+1.0)+1.0/(1.0*x0+1.0)))+1.0\"\n",
    "    complex_8 = \"1.0*x0**2+1.0*x0+1.0*exp(1.0*x0)/1.0*sqrt(1.0*abs(1.0*sqrt(1.0*abs(1.0*x0+1.0))))+1.0\"\n",
    "\n",
    "\n",
    "    sample_meta = {complex_1: (-.9, 1., number_points, -3,-1.1,1, 3),\n",
    "                   complex_2: (-.9, 1., number_points, -3,-1.1,1, 3),\n",
    "                   complex_3: (-0.9, 1., number_points, -3,-1,1, 3),\n",
    "                   complex_4: (0.1, 2., number_points, 2, 3, 3, 4),\n",
    "                   complex_5: (1.01, 2, number_points, 2, 3, 3, 4),\n",
    "                   complex_6: (-.9, 3., number_points, 3, 5, 5, 7),\n",
    "                   complex_7: (-0.9, 1., number_points, -3,-1.1, 1, 3),\n",
    "                   complex_8: (-0.9, 1., number_points, -3,-1.1, 1, 3),              }\n",
    "    set_name = \"generated_complex\"\n",
    "    \n",
    "elif(1):\n",
    "    complex_1 = \"sin(x0 * exp(x0))\"\n",
    "    complex_2 = \"x0 + log(x0**4)\"\n",
    "    complex_3 = \"1+x0*sin(1/x0)\"\n",
    "    complex_4 = \"sqrt(x0**3) * log(x0**2)\"\n",
    "    complex_5 = \"(x0+x0**3) / (1+x0*cos(x0**2))\"\n",
    "    complex_6 = \"x0 / (sqrt(x0**2 + sin(x0)))\"\n",
    "    complex_7 = \"cos((x0+sin(x0))/ (x0**3+x0*log(x0**2)))\"\n",
    "    complex_8 = \"(exp(x0) * (1+sqrt(1+x0) + cos(x0**2)))/ x0**2\"\n",
    "\n",
    "    # sampling meta are (a,b,c,d,e,f,g) tuples, e.g. c samples in the range from a to b\n",
    "    # d,e and f,g are the min and max values for validation input ranges\n",
    "\n",
    "    sample_meta = {complex_1: (-5., 5., number_points, -7,-5, 5,7),\n",
    "                   complex_2: (-5., 5., number_points, -7,-5, 5,7),\n",
    "                   complex_3: (-5., 5., number_points, -7,-5, 5,7),\n",
    "                   complex_4: (-5., 5., number_points, -7,-5, 5,7),\n",
    "                   complex_5: (-1., .5, number_points, -2, -1., .5, 1.25),\n",
    "                   complex_6: (-5., 5., number_points, -7,-5, 5,7),\n",
    "                   complex_7: (-5., 5., number_points, -7,-5, 5,7),\n",
    "                   complex_8: (.1, 5., number_points, -7,-5, 5,7),\n",
    "                  }            \n",
    "\n",
    "    set_name = \"AB_complex\"\n",
    "    \n",
    "    \n",
    "benchmark_eqns = [complex_1, complex_2, complex_3, complex_4, \\\n",
    "        complex_5, complex_6, complex_7, complex_8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb8c16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize equations\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "for number, fn in enumerate(benchmark_eqns):\n",
    "\n",
    "    my_fn = sp.lambdify(\"x0\", expr=fn)\n",
    "    \n",
    "    (bottom, top, c,d,e,f,g) = sample_meta[fn]\n",
    "    \n",
    "    step_size = (top-bottom)/10000\n",
    "    \n",
    "    x = np.arange(bottom, top, step_size)\n",
    "    \n",
    "    my_color = my_cmap(number/len(benchmark_eqns))\n",
    "    plt.plot(x, my_fn(x), color=my_color, label = f\"{set_name}-{1+number}\")\n",
    "    \n",
    "plt.legend()\n",
    "plt.title(f\"{set_name} benchmark equations\")\n",
    "\n",
    "plt.figure()\n",
    "for number, fn in enumerate(benchmark_eqns):\n",
    "\n",
    "    my_fn = sp.lambdify(\"x0\", expr=fn)\n",
    "    \n",
    "    (bottom, top, c,d,e,f,g) = sample_meta[fn]\n",
    "    \n",
    "    step_size = (top-bottom)/10000\n",
    "    \n",
    "  \n",
    "    x = np.arange(d,e, step_size)\n",
    "    my_color = my_cmap(number/len(benchmark_eqns))\n",
    "    plt.plot(x, my_fn(x), color=my_color, label= f\"{set_name}-{1+number} val\", alpha=0.69)\n",
    "       \n",
    "plt.legend()\n",
    "\n",
    "for number, fn in enumerate(benchmark_eqns):\n",
    "\n",
    "    my_fn = sp.lambdify(\"x0\", expr=fn)\n",
    "    \n",
    "    (bottom, top, c,d,e,f,g) = sample_meta[fn]\n",
    "    \n",
    "    step_size = (top-bottom)/10000\n",
    "  \n",
    "    x = np.arange(f,g, step_size)\n",
    "    my_color = my_cmap(number/len(benchmark_eqns))\n",
    "    plt.plot(x, my_fn(x), color=my_color, label= f\"{set_name}-{1+number} val\", alpha=0.69)\n",
    "\n",
    "plt.title(f\"{set_name} benchmark validation regions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc5b699",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "eval_tag = f\"eval_complex_{my_method}_{int(time.time())}\"\n",
    "columns = \"eqn, seed, pred, target, correct, mse,  r2_ood, r2_id,\"\n",
    "columns += \"target_complexity, complexity, method, range_low, range_high, \"\n",
    "columns += \"number_points, val_low0, val_high0, val_lo1, val_high1\"\n",
    "\n",
    "\n",
    "if logging:\n",
    "    with open(f\"{eval_tag}.csv\", \"w\") as f:\n",
    "        f.write(columns)\n",
    "        f.write(\"\\n\")\n",
    "    \n",
    "accuracies = []\n",
    "all_mses = []\n",
    "all_mse_sds = []\n",
    "\n",
    "all_r2_means = []\n",
    "all_r2_sds = []\n",
    "all_tree_distances = []\n",
    "all_ares = []\n",
    "\n",
    "all_tree_distance_sds = []\n",
    "all_are_sds = []\n",
    "\n",
    "catastrophic_failure_count = 0\n",
    "\n",
    "for hh, eqn in enumerate(benchmark_eqns):\n",
    "    \n",
    "    equivalents = []\n",
    "    mses = []\n",
    "    r2s = []\n",
    "    complexities = []\n",
    "    ares = []\n",
    "    tree_distances = []\n",
    "    \n",
    "    target_complexity = compute_complexity(eqn)\n",
    "    \n",
    "    for trial in range(number_trials):\n",
    "\n",
    "        np.random.seed(trial)\n",
    "        torch.manual_seed(trial)\n",
    "        \n",
    "        my_fn = sp.lambdify(\"x0\", expr=eqn)\n",
    "        \n",
    "        (bottom, top, number_samples, d, e, f, g) = sample_meta[eqn]\n",
    "        x = np.random.rand(number_samples, 1) \\\n",
    "                * (top-bottom) \\\n",
    "                + bottom\n",
    "        y = my_fn(x)\n",
    "        \n",
    "        model = PySRRegressor(\n",
    "            niterations=10,\n",
    "            binary_operators=[\"+\", \"*\", \"/\", \"-\"],\n",
    "            unary_operators=[\n",
    "                \"cos\",\n",
    "                \"exp\",\n",
    "                \"sin\",\n",
    "                \"sqrt\"\n",
    "                #\"inv(x) = 1/x\"  # Custom operator (julia syntax)\n",
    "            ],\n",
    "            model_selection=\"best\",\n",
    "            deterministic = True,\n",
    "            procs = 0,\n",
    "            multithreading = False,\n",
    "            random_state = trial,\n",
    "            verbosity=0,\n",
    "            loss=\"loss(x, y) = (x - y)^2\",  # Custom loss function (julia syntax)\n",
    "        )\n",
    "        try:\n",
    "\n",
    "            model.fit(x, y)\n",
    "\n",
    "            if \"bs\" in model.get_best()[\"equation\"]:\n",
    "                print(\"abs detected\")\n",
    "\n",
    "            #if (x >= 0).all():\n",
    "            # remove abs() if input only consists of positive numbers\n",
    "            if \"abs\" in model.get_best()[\"equation\"]:\n",
    "                best_eqn = sp.simplify(model.get_best()[\"equation\"]\\\n",
    "                                       .replace(\"inv(\", \"1./(\").replace(\"abs\", \"\").replace(\"_\",\"\"))\n",
    "                best_fn = sp.lambdify(\"x0\", expr=model.get_best()[\"equation\"]\\\n",
    "                                      .replace(\"inv(\", \"1./(\").replace(\"abs\", \"\").replace(\"_\",\"\"))\n",
    "\n",
    "                tgt_fn = sp.lambdify(\"x0\", expr=eqn)\n",
    "            else:\n",
    "                best_eqn = sp.simplify(model.get_best()[\"equation\"].replace(\"inv(\", \"1./(\").replace(\"_\",\"\"))\n",
    "                best_fn = sp.lambdify(\"x0\", expr=model.get_best()[\"equation\"].replace(\"inv(\", \"1./(\").replace(\"_\",\"\"))\n",
    "\n",
    "                tgt_fn = sp.lambdify(\"x0\", expr=eqn)\n",
    "            if \"abs\" in eqn:\n",
    "                tgt_eqn = sp.simplify(eqn.replace(\"abs\", \"\"))\n",
    "                tgt_fn = sp.lambdify(\"x0\", expr=eqn)\n",
    "            else:\n",
    "                tgt_eqn = sp.simplify(eqn)\n",
    "                tgt_fn = sp.lambdify(\"x0\", expr=eqn)\n",
    "\n",
    "            is_correct = sp.simplify(best_eqn - tgt_eqn) == 0\n",
    "            my_mse = np.mean((tgt_fn(x) - best_fn(x))**2)\n",
    "            id_x = np.arange(bottom, top, (top-bottom)/1000).reshape(-1, 1)\n",
    "\n",
    "            bigger_x = np.append(np.arange(d,e, (e-d)/500).reshape(-1, 1),\\\n",
    "                                 np.arange(f,g, (g-f)/500).reshape(-1,1))\n",
    "\n",
    "            bigger_y_true = tgt_fn(bigger_x)\n",
    "            bigger_y_pred = best_fn(bigger_x)\n",
    "\n",
    "            id_y_true = tgt_fn(id_x)\n",
    "            id_y_pred = best_fn(id_x)\n",
    "\n",
    "            if np.isfinite(bigger_y_pred.mean()):\n",
    "                my_r2 = sklearn.metrics.r2_score(bigger_y_true, bigger_y_pred)\n",
    "            else:\n",
    "                my_r2 = np.nan\n",
    "\n",
    "            if np.isfinite(id_y_pred.mean()):\n",
    "                my_r2_id = sklearn.metrics.r2_score(id_y_true, id_y_pred)\n",
    "            else:\n",
    "                my_r2_id = np.nan\n",
    "\n",
    "\n",
    "            \n",
    "            my_complexity = compute_complexity(best_eqn)\n",
    "            my_ted = compute_tree_distance(eqn, best_eqn)\n",
    "            my_are = compute_relative_error(id_y_true, id_y_pred)\n",
    "\n",
    "            complexities.append(my_complexity)\n",
    "            mses.append(my_mse)\n",
    "            r2s.append(my_r2_id)\n",
    "            equivalents.append(is_correct)\n",
    "\n",
    "            tree_distances.append(my_ted)\n",
    "            ares.append(my_are)\n",
    "\n",
    "            wright = \"correct\" if is_correct else \"incorrect\"\n",
    "            correct = 1 if is_correct else \"incorrect\"\n",
    "\n",
    "            try:\n",
    "                msg = f\"eqn {hh+1}, trial {trial} predicted {wright} equation {best_eqn} for target {tgt_eqn}\"\n",
    "                msg += f\" with mse {my_mse:.3}, r2 = {my_r2:.4}, and complexity {my_complexity}/{target_complexity}\"\n",
    "            except:\n",
    "                msg = \"\"\n",
    "            print(msg)\n",
    "\n",
    "            #columns = \"eqn, seed, pred, target, correct, mse, method, range_low, range_high, r2, number_points\"\n",
    "            if logging:\n",
    "                results = f\"{eqn}, {hh}, {best_eqn}, {tgt_eqn}, {correct}, {my_mse}, {my_r2}, \"\\\n",
    "                        f\"{my_r2_id}, {target_complexity}, {my_complexity}, \"\\\n",
    "                        f\" {my_method}, {bottom}, {top}, {number_samples}, {d}, {e}, {f}, {g}\"\n",
    "\n",
    "                with open(f\"{eval_tag}.csv\", \"a\") as f:\n",
    "                    f.write(results)\n",
    "                    f.write(\"\\n\")\n",
    "                    \n",
    "        except:\n",
    "            print(\"catastrophic fail of some kind\")\n",
    "            catastrophic_failure_count += 1\n",
    "            \n",
    "    msg = f\"accuracy for equation {hh+1}: {np.mean(equivalents)}\"\\\n",
    "            f\" with mean mse: {np.mean(mses):3}, r2 = {np.mean(r2s)},\"\\\n",
    "            f\" and avg. complexity {np.mean(complexities)}\"\n",
    "\n",
    "    if len(mses):\n",
    "        accuracies.append(np.mean(equivalents))\n",
    "        all_mses.append(np.mean(mses))\n",
    "        all_mse_sds.append(np.std(mses))\n",
    "        all_r2_means.append(np.mean(r2s))\n",
    "        all_r2_sds.append(np.std(r2s))\n",
    "\n",
    "        all_ares.append(np.mean(ares))\n",
    "        all_tree_distances.append(np.mean(tree_distances))\n",
    "\n",
    "        all_are_sds.append(np.std(ares))\n",
    "        all_tree_distance_sds.append(np.std(tree_distances))\n",
    "    else:\n",
    "        accuracies.append(0.0)\n",
    "        all_mses.append(float(\"inf\"))\n",
    "        all_mse_sds.append(float(\"inf\"))\n",
    "        all_r2_means.append(-float(\"inf\"))\n",
    "        all_r2_sds.append(float(\"inf\"))\n",
    "\n",
    "        all_ares.append(float(\"inf\"))\n",
    "        all_tree_distances.append(float(\"inf\"))\n",
    "\n",
    "        all_are_sds.append(float(\"inf\"))\n",
    "        all_tree_distance_sds.append(float(\"inf\"))\n",
    "        \n",
    "failure_msg = f\"\\nTotal failure count: {catastrophic_failure_count}, of {len(benchmark_eqns)*number_trials}\"\n",
    "failure_msg += f\" = {catastrophic_failure_count / (len(benchmark_eqns)*number_trials)}\"\n",
    "print(failure_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5331369c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "msg = f\"{my_method} accuracies\\n\"\n",
    "print(failure_msg)\n",
    "\n",
    "for ii, eqn in enumerate(benchmark_eqns):\n",
    "    \n",
    "    msg += f\"\\n  complex-{ii+1}, exact equ. accuracy: {accuracies[ii]:5f}, \"\\\n",
    "            f\"\\ntree edit distance: {all_tree_distances[ii]:.5} +/- {all_tree_distance_sds[ii]:.5} \"\\\n",
    "            f\"\\nmse: {all_mses[ii]:.5} +/- {all_mse_sds[ii]:.5} \"\\\n",
    "            f\"\\nrelative absolute error: {all_ares[ii]:.5} +/- {all_are_sds[ii]:.5} \"\\\n",
    "            f\"\\nr^2 (i.d): {all_r2_means[ii]:.5} +/- {all_r2_sds[ii]:.5}\\n\\n\"\n",
    "    \n",
    "    msg += f\"  {sp.expand(eqn)} \\n\"\n",
    "\n",
    "if logging:\n",
    "    summary_file = f\"{eval_tag}_summary.txt\"\n",
    "    with open(summary_file, \"w\") as f:\n",
    "        f.write(msg)\n",
    "        \n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ebde2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
